{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coated-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torchvision.transforms import Compose, CenterCrop, Normalize, ToTensor\n",
    "from pytorch_wavelets import DWT1DForward, DWT1DInverse  # or simply DWT1D, IDWT1D\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-walter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "governing-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "test_size = 64\n",
    "Noise = \"4_db\"\n",
    "\n",
    "def Normalization(data):\n",
    "    \n",
    "    data_mean = data.mean()\n",
    "    data_std = data.std()\n",
    "    \n",
    "    data = data - data_mean\n",
    "    data = data / data_std\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banner-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#print(train_loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "domestic-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root  \n",
    "        if not os.path.exists(self.root):\n",
    "            raise Exception(\"[!] {} not exists.\".format(root))\n",
    "        \n",
    "        #sort file names\n",
    "        self.input_paths = sorted(glob(os.path.join(self.root, '{}/*_train.npy'.format(\"GB_data/Real/noise_data/\"+Noise+\"/train_data\"))))\n",
    "        self.label_paths = sorted(glob(os.path.join(self.root, '{}/*_lab.npy'.format(\"GB_data/Real/noise_data/\"+Noise+\"/train_lab\"))))\n",
    "        self.name = os.path.basename(root)\n",
    "        \n",
    "        #print(self.input_paths)\n",
    "        #print(self.label_paths)\n",
    "        \n",
    "        if len(self.input_paths) == 0 or len(self.label_paths) == 0:\n",
    "            raise Exception(\"No signal/labels are found in {}\".format(self.root))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        Signal = np.load(self.input_paths[index])\n",
    "        Signal = Normalization(Signal)\n",
    "        \n",
    "        Label = np.load(self.label_paths[index])\n",
    "            \n",
    "        return Signal, Label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_paths)\n",
    "    \n",
    "class Dataset_test(torch.utils.data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        \n",
    "        if not os.path.exists(self.root):\n",
    "            raise Exception(\"[!] {} not exists.\".format(root))\n",
    "        \n",
    "        #sort file names\n",
    "        self.input_paths = sorted(glob(os.path.join(self.root, '{}/*_test.npy'.format(\"GB_data/Real/noise_data/\"+Noise+\"/test_data\"))))\n",
    "        self.label_paths = sorted(glob(os.path.join(self.root, '{}/*_lab.npy'.format(\"GB_data/Real/noise_data/\"+Noise+\"/test_lab\"))))\n",
    "        self.name = os.path.basename(root)\n",
    "        \n",
    "        if len(self.input_paths) == 0 or len(self.label_paths) == 0:\n",
    "            raise Exception(\"No sinagl/labels are found in {}\".format(self.root))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        Signal = np.load(self.input_paths[index])\n",
    "        Signal = Normalization(Signal)\n",
    "        \n",
    "        Label = np.load(self.label_paths[index])\n",
    "        \n",
    "        return Signal, Label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(dataset, batch_size, num_workers=0, shuffle = False, drop_last=False):\n",
    "\n",
    "    input_images = dataset\n",
    "    input_loader = torch.utils.data.DataLoader(dataset=input_images, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
    "\n",
    "    return input_loader\n",
    "\n",
    "train_loader = loader(Dataset('../../'), batch_size= batch_size, shuffle = True, drop_last=True)\n",
    "test_loader = loader(Dataset_test('../../'), batch_size= test_size, shuffle = True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d82db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_cSE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_ch):\n",
    "        super(A_cSE, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, in_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, int(in_ch/2), kernel_size=1, padding=0),\n",
    "            nn.BatchNorm1d(int(in_ch/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(int(in_ch/2), in_ch, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm1d(in_ch)\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_x):\n",
    "        \n",
    "        x = self.conv0(in_x)\n",
    "        x = nn.AvgPool1d(x.size()[2:])(x)\n",
    "        #print('channel',x.size())\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return in_x * x + in_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 1\n",
    "numf =12\n",
    "\n",
    "class SConv_1D(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch, kernel, pad):\n",
    "        super(SConv_1D, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel, padding=pad),\n",
    "            nn.GroupNorm(6, out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        \n",
    "        self.DWT0= DWT1DForward(J=1, wave='db16').cuda()\n",
    "        \n",
    "        self.SConv1 = SConv_1D(input*2, numf, 3, 0)\n",
    "        self.DWT1= DWT1DForward(J=1, wave='db16').cuda()\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.cSE1 = A_cSE(numf*2)\n",
    "        \n",
    "        self.SConv2 = SConv_1D(numf*2, numf*2, 3, 0)\n",
    "        self.DWT2= DWT1DForward(J=1, wave='db16').cuda() \n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        self.cSE2 = A_cSE(numf*4)\n",
    "        \n",
    "        self.SConv3 = SConv_1D(numf*4, numf*4, 3, 0)\n",
    "        self.DWT3= DWT1DForward(J=1, wave='db16').cuda()       \n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "        self.cSE3 = A_cSE(numf*8)\n",
    "        \n",
    "        self.SConv6 = SConv_1D(numf*8, numf*8, 3, 0)              \n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d((1))\n",
    "        self.fc = nn.Linear(numf*8, 6)\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        DMT_yl,DMT_yh = self.DWT0(input)\n",
    "        output = torch.cat([DMT_yl,DMT_yh[0]], dim=1)\n",
    "        \n",
    "        output = self.SConv1(output)\n",
    "        DMT_yl,DMT_yh = self.DWT1(output)\n",
    "        output = torch.cat([DMT_yl,DMT_yh[0]], dim=1)\n",
    "        output = self.dropout1(output)\n",
    "        output = self.cSE1(output)\n",
    "        \n",
    "        output = self.SConv2(output)\n",
    "        DMT_yl,DMT_yh = self.DWT2(output)\n",
    "        output = torch.cat([DMT_yl,DMT_yh[0]], dim=1) \n",
    "        output = self.dropout2(output)\n",
    "        output = self.cSE2(output)\n",
    "        \n",
    "        output = self.SConv3(output)\n",
    "        DMT_yl,DMT_yh = self.DWT3(output)\n",
    "        output = torch.cat([DMT_yl,DMT_yh[0]], dim=1) \n",
    "        output = self.dropout3(output)\n",
    "        output = self.cSE3(output)\n",
    "        \n",
    "        output = self.SConv6(output)             \n",
    "            \n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-terrace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = CNN_1D().to(device)\n",
    "\n",
    "print(Model)\n",
    "\n",
    "print('# Model parameters:', sum(param.numel() for param in Model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "Criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "Optimizer = torch.optim.Adam(Model.parameters(), lr=0.0001)\n",
    "\n",
    "#scheduler = optim.lr_scheduler.StepLR(Optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-wilson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc  = []\n",
    "\n",
    "for epoch in range(150):\n",
    "    \n",
    "    train_loss_sum, test_loss_sum, train_num, test_num, train_i, test_i = 0.0, 0.0, 0, 0, 0, 0\n",
    "    train_acc_sum,test_acc_sum = 0, 0\n",
    "    TEST_acc_sum = 0\n",
    "    \n",
    "    for i_1, train_data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels = train_data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.long()\n",
    "        labels = labels.squeeze(1)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #print(inputs.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        Model.train()\n",
    "        pre_labs = Model(inputs)\n",
    "\n",
    "        Loss = Criterion(pre_labs, labels)\n",
    "\n",
    "        Optimizer.zero_grad()\n",
    "        Loss.backward()\n",
    "        Optimizer.step()\n",
    "        \n",
    "        train_loss_sum += Loss.item()\n",
    "        train_acc_sum += (pre_labs.argmax(dim=1) == labels).sum().item()\n",
    "        train_num += labels.shape[0]\n",
    "        train_i += 1\n",
    "\n",
    "    for i_2, data in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            test_data, test_lab = data  \n",
    "            test_data = test_data.unsqueeze(1)\n",
    "            test_data = test_data.type(torch.FloatTensor)\n",
    "            test_data = test_data.to(device)\n",
    "            test_lab = test_lab.long()\n",
    "            test_lab = test_lab.squeeze(1)\n",
    "            test_lab = test_lab.to(device)\n",
    "\n",
    "            Model.eval()\n",
    "            pre_test = Model(test_data)\n",
    "            t_loss = Criterion(pre_test, test_lab)\n",
    "\n",
    "            test_loss_sum += t_loss    \n",
    "            test_acc_sum += (pre_test.argmax(dim=1) == test_lab).sum().item()\n",
    "            test_num += test_lab.shape[0]                    \n",
    "            test_i += 1\n",
    "            \n",
    "            #_, Pred = torch.max(pre_test.data, 1)\n",
    "            #TEST_acc_sum += torch.sum(Pred == test_lab)\n",
    "           \n",
    "    if epoch >= 120:\n",
    "        #torch.save(Model, \"model/DWA_0/CNN_%d.pkl\"% epoch)\n",
    "        print(\"-------保存第%d epoch的模型---------\"% epoch)\n",
    "       \n",
    "    Train_Loss = train_loss_sum/train_i\n",
    "    Test_Loss = test_loss_sum/test_i\n",
    "    Train_ACC = train_acc_sum/train_num\n",
    "    Test_ACC = test_acc_sum/test_num\n",
    "\n",
    "    print('Epoch:%d, train_loss:%.5f, train_acc:%.5f, test_loss:%.5f, test_acc:%.5f' % \n",
    "          (epoch, Train_Loss, Train_ACC, Test_Loss, Test_ACC))\n",
    "    print('-----------------------------------------------')\n",
    "\n",
    "    train_loss.append(Train_Loss)            \n",
    "    train_acc.append(Train_ACC) \n",
    "    test_loss.append(Test_Loss) \n",
    "    test_acc.append(Test_ACC)       \n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-possession",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('train_acc:')\n",
    "print(train_acc)\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('test_acc:')\n",
    "print(test_acc)\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('The max test_acc:')\n",
    "print(max(test_acc[100:]))\n",
    "\n",
    "\n",
    "X_epoch = np.zeros((150))\n",
    "for id in range(150):\n",
    "    X_epoch[id] = id\n",
    "\n",
    "fig = plt.figure(figsize=[8,5])\n",
    "sub = fig.add_subplot(111)\n",
    "\n",
    "sub.plot(X_epoch, train_acc, c='orange', label='Train Accuracy', linewidth=2)\n",
    "sub.plot(X_epoch, test_acc, c='lime', label='Test Accuracy', linewidth=2)\n",
    "\n",
    "ax=plt.gca();#获得坐标轴的句柄\n",
    "ax.spines['bottom'].set_linewidth(1.5);###设置底部坐标轴的粗细\n",
    "ax.spines['left'].set_linewidth(1.5);####设置左边坐标轴的粗细\n",
    "ax.spines['right'].set_linewidth(1.5);###设置右边坐标轴的粗细\n",
    "ax.spines['top'].set_linewidth(1.5);####设置上部坐标轴的粗细\n",
    "\n",
    "plt.tick_params(labelsize=14)\n",
    "\n",
    "plt.legend(loc=4, edgecolor='w')\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "#plt.title('curve')\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig('Image/WaveCNet-db16.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-appraisal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-legislature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-voltage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-agency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
